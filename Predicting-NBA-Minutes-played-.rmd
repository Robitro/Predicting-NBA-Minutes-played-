---
title: "Predicting NBA Minutes played"
Author: "Robert Miller"
output: html_document
date: "2022-12-09"
code_folding: hide
toc: true

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,fig.width = 10, fig.height = 5)


devtools::install_github("abresler/nbastatR")
library(nbastatR)
library(tidymodels)
library(corrplot)
library(tidyverse)
library(dplyr)
library(ggplot2)
library(pracma)
library(xgboost)
library(kknn)
library(randomForest)
library(ranger)

```
Data cleaning

```{r, eval=FALSE}
seq <- seq(22100001,22101320,8)
box_team<- box_scores(seq,box_score_types = c("Traditional", "Advanced"),result_types = "team", join_data = TRUE) 

get_seasons_rosters(seasons = 2021:2022, return_message = TRUE, nest_data = F)

save(box_team,file="box_team.rda")

box_player <-  box_scores(seq,box_score_types = c("Traditional", "Advanced"),result_types = "player", join_data = TRUE)
save(box_player,file = "box_player.rda")



```
```{r}

load(file = "box_team.rda")

load(file = "box_player.rda")

player <- box_player[[2]][[1]]

player$groupStartPosition[is.na(player$groupStartPosition)] <- "Bench"
player$groupStartPosition[player$groupStartPosition == "C"] <- "Center"
player$groupStartPosition[player$groupStartPosition == "F"] <- "Forward"
player$groupStartPosition[player$groupStartPosition == "G"] <- "Guard"









  
  
```
Data from this project was scraped from the NBA website using NBAstatR, an R package designed to pull data from various basketball databases on the internet. Here we have taken a subset of 165 games of the 1320 games played in the 2021-2022 NBA season pulling every 8 games from the very start to very finish in the regular season.

```{r,fig.dim = c(10,10)}
#removes ID's from correlation plot 
player_no_id <- select(player, -c("idTeam","idGame","idPlayer"))

correlation <- cor(select_if(player_no_id,is.numeric))


corrplot(correlation,type = 'lower', diag = FALSE, method='color')

```
Let's take a look at the distribution of minutes played by position.
```{r}
ggplot(player, aes(minExact)) + geom_histogram(binwidth = 5, fill = "blue", color = "red") + facet_wrap(~groupStartPosition)



summary(player$minExact[player$groupStartPosition=="Center"])
summary(player$minExact[player$groupStartPosition=="Forward"])
summary(player$minExact[player$groupStartPosition=="Guard"])
summary(player$minExact[player$groupStartPosition=="Bench"])
```
As we can see, Starters tend to average around 30 minutes of the 48 minutes of playing time in basketball, with a sharp drop-off of observations below 20 minutes and above 35 minutes. Center observations are much lower than centers and forwards since there are 2 guards and 2 forwards on the floor but only 1 center at any given time. For players coming off of the bench, the observations are skewed towards lower minutes (as they are often not good enough to play lots of minutes).

```{r}
ggplot(player,aes(minExact,pts)) + geom_point(aes(colour = cut(fga,c(-Inf,5,10,15,20,25,35,Inf))),size = 2) + facet_wrap(~groupStartPosition) + scale_color_manual(name = "Field Goals Attempted", 
values = c("green", "yellow", "orange", "blue", "violet","red"),
labels = c("0-5", "5-10", "10-15", "15-20","20-25","> 25"))
```
Basketball is grouped into 3 groups (guards, forwards, centers) and 5 positions (point guard, shooting guard, small forward, power forward, and center). As we can see, the more minutes a player plays there is an upward trajectory in points scored as well as shot attempts. This makes sense as the only way to score points is to shoot field goals or shoot free throws, and to shoot free-throws you need to be fouled which often occurs when a player is trying to make a shot. Bench players tend to shoot less field goals and guards seem to shoot the most.
```{r}

ggplot(player, aes(minExact,pctFG3)) + geom_point(aes(colour = cut(fg3a,breaks = c(-Inf,0,1,2,4,6,8,10,Inf))),size = 2) + facet_wrap(~groupStartPosition) + scale_color_manual(name = "3 Point Field Goals Attempted", 
values = c("purple","pink","green", "yellow", "orange", "blue", "violet","red"),
labels = c("0", "1", "1-2", "2-4", "4-6","6-8","8-10", "> 10"))


```
As we can see both 3 point percentage and attempts is very dependent on minutes played. Centers shoot far fewer threes than guards and  forwards as a result of their often larger size prefer to shoot around the rim. Furthermore, We can also see that as minutes increase there is a decrease in 3 point efficiency. There are bands around 0%,50%, 100% is usally a result of players taking only a couple threes and hitting or missing all of them. In the 2021-2022 season the league wide average shooting percentage was 35.4% (source:basketballreference.com)

Scoring is a large part of the NBA but there are some players that play large chunks of minutes in an NBA game that are not known for their scoring prowess. Let's look at rebounds, a stat that counts the number of balls caught after a shot hits the rim or backboard in a game.

```{r}
ggplot(player,aes(minExact, treb, group=minExact, fill=oreb))+ geom_col() + scale_x_discrete(breaks = seq(0,50,5))+facet_wrap(~groupStartPosition)

```

```{r}

ggplot(player, aes(minExact,netrtg)) + geom_point() + facet_wrap(~groupStartPosition) 



```

Net rating is defined as offensive rating vs defensive rating. Offensive rating is a measure of how may points are scored by the player per 100 possessions of the basketball and defensive rating is measure of how many points they give up on defense per 100 possessions. If more points are scored then given up, this will result in a positive net rating. The best players often average a high positive net rating, for example Nikola Jokic: a 6'11 Serbian Center that plays for the Denver Nuggets averaged net ratings of 14.8 in 20-21 season and 10.4 in 21-22 season (source:basketballreference.com), earning him back to back most valuable player awards. High net ratings may be a good predictor of many minutes played, but astronomically high or low net ratings are a result of a small sample size which may be a good predictor for players playing few minutes.


## The Split
```{r}
set.seed(6688)
player_split <- initial_split(player, prop=.7, strata = minExact) 

player_train <- training(player_split)
player_test <- testing(player_split)

player_folds <- vfold_cv(player_train, v = 5, stata = minExact)

```
We will now create a 70/30 training vs testing split stratifying on the minutes an NBA player plays, we will then create our recipe using our training data to predict the number of minutes an NBA player plays in a game. A 5 fold cross validation of our training set was also created, which we will use in order to predict which model will preform best at predicting minutes played.

```{r}

min_re <- recipe(minExact ~ pts+oreb+dreb+ast+fg3a+fg3m+blk+pf+tov+fg2a+fg2m+fta+ftm+pctUSG+ortg+drtg+possessions+plusminus+pace+tov+pctTOVTeam, data = player_train) %>% step_dummy(all_nominal_predictors()) %>% step_center(all_numeric_predictors()) %>% step_scale(all_numeric_predictors())


```

Here's our recipe for predicting minutes played. We're using points scored, offensive and defensive rebounds, assists(where a player passes a ball to another player who score a basket),3 points attempted and made, blocks, personal fouls (6 fouls will result in ejection), turnovers, 2 pointers attempted and made, free throws attempted and made, Usage rate(the percent of possessions where the player is involved in the play), Offensive and Defensive rating, the number of possessions, box plus minus (a measure where 0 is league average positive is the number of extra points per 100 possessions and negative is the number of points given up above average), starting position,and turnovers(losing the ball to the other team) and percentage of turnovers commited by the player from total team turnovers.


#### Model Setup


## Elastic Net
```{r}
en <- linear_reg(penalty = tune(),mixture = tune()) %>% set_mode("regression") %>% 
  set_engine("glmnet")


en_wflow <- workflow() %>% 
  add_model(en) %>% 
  add_recipe(min_re)

en_grid <- grid_regular(penalty(c(-5,5)),mixture(c(0,1)),levels = 10)

```
The first model we will fit will be elastic net regression, a regularized regression model which combines ridge and lasso coefficients to fit a linear model on our data. We are tuning our penalty model from -5-5 and our mixture from 0-1, a mixture of 1 represents pure lasso regression and a mixture of 0 represents pure ridge regression. 


## K-Nearest Neighbors
```{r}

knn <- nearest_neighbor(
  neighbors = tune(),
  weight_func = tune()
) %>%  
  set_engine("kknn") %>% 
  set_mode("regression")

knn_wflow <-
  workflow() %>% 
  add_model(knn) %>% 
  add_recipe(min_re)

knn_grid <- grid_regular(neighbors(c(1,50)),weight_func(c("rectangular", "triangular", "epanechnikov", "biweight", "triweight", "cos", "inv", "gaussian", "rank", "optimal")),levels= 10)


```
k-nearest neighbors works by looking at the k closest data points and works to assign a value similar to those data points. We are tuning the model by the number of neighbors from 1-50, and all of the possible weight functions to determine the optimal KNN model for our dataset.

## Boosted Trees
```{r}
bt <- boost_tree() %>% set_engine("xgboost") %>% set_mode("regression")

bt_wf <- workflow() %>% add_model(bt %>% set_args(trees = tune(), tree_depth = tune())) %>% add_recipe(min_re)

tree_grid <- grid_regular(trees(range= c(2,1000)), tree_depth(range = c(1,10)),levels = 10)


```

## Random Forest
```{r}
rf <- rand_forest() %>% set_engine("ranger", importance = "impurity") %>% set_mode("regression")

rf_wf <- workflow() %>% add_model(rf %>% set_args(mtry = tune(), trees = 128 ,min_n = tune())) %>% add_recipe(min_re)

rand_grid <- grid_regular(mtry(range= c(1,20)), min_n(range = c(1,5)),levels = 8)


```



### Tuning

```{r}
load(file = "tune_elas.rda")
autoplot(tune_elas)
```

```{r}
load(file = "tune_knn.rda")
autoplot(tune_knn)
```

```{r}
load(file = "tune_tree.rda")
autoplot(tune_tree)
```

```{r}
metrics_boost <- collect_metrics(tune_tree) %>% arrange(desc(mean))
metrics_boost
best_bt <- select_best(tune_boost)

bt_wf_f <- finalize_workflow(bt_wf,best_bt)

bt_final_fit <- fit(bt_wf_f,starter_train)

rsq <- metric_set(rsq)

min_pred <- predict(bt_final_fit,starter_test) %>%  bind_cols(starter_test %>% select(minExact))

rsq(min_pred, truth = minExact, estimate = .pred)



```